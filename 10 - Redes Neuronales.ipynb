{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "**Aprendizaje Automático - Instituto de Computación - UdelaR**\n",
    "\n",
    "En este módulo, presentaremos una introducción a las redes neuronales, un modelo que permite aprender funciones continuas o discretas a partir de ejemplos. Existen algoritmos (como backpropagation), que permiten ajustar eficientemente los parámetros de la red utilizando descenso por gradiente, lo que ha permitido su utilización en múltiples tareas y dominios. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Redes Neuronales\n",
    "\n",
    "Supongamos que tenemos una tarea de clasificación supervisada donde, a partir de un vector $x^T = (x_1, x_2, \\ldots, x_n)$ con $n$ _atributos_ se busca construir una función (hipótesis) $h_{\\theta}(x): \\mathbb{R}^{n} \\to \\mathbb{R}$ que prediga la salida $y \\in \\mathbb{R}$ (que podemos considerar discreta), a partir de un conjunto de entrenamiento. El problema de aprendizaje para las redes neuronales consiste en aprender los parámetros $\\theta$ a partir de un conjunto de entrenamiento $\\{(x^{(i)},y^{(i)})\\}$ que tiene $m$ elementos y donde cada $(x^{(i)},y^{(i)})$ es una _instancia_ de entrenamiento. Este escenario es exactamente igual al planteado para regresión logística. \n",
    "\n",
    "Si la función de hipótesis $h_{\\theta}(x)$ no es lineal, sabemos que podemos utlizar atributos no lineales, resultado de la combinación de atributos de entrada, y aplicar regresión logística. El problema con esta aproximación es que el número de parámetros crecerá exponencialmente con la cantidad de atributos, lo que vuelve computacionalmente imposible el problema cuando el número de atributos crece. Las redes neuronales permiten aprender hipótesis complejas de forma eficiente, aun cuando el número de atributos de entrada es muy grande. \n",
    "\n",
    "Dado un vector de entrada  $x^T = (x_1, x_2, \\ldots, x_n)$ , la red neuronal más simple que puede construirse es equivalente a la regresión logística, y está compuesta por una primera capa de neuronas con los atributos de entrada (a lo que llamaremos _capa de entrada_, y denotaremos también como $a^{(1)})$, y una segunda capa compuesta por una sola neurona (o _unidad sigmoide_), que calcula la combinación lineal de las entradas y le aplica la función sigmoide (llamada _función de activación_), para obtener una salida real. \n",
    "\n",
    "Por lo tanto:\n",
    "\n",
    "$$ x \\in  \\mathbb{R}^{n} = a^{(1)} = \\left[ \\begin{array}{c} x_0\\\\\\vdots\\\\x_n \\end{array}\\right]$$\n",
    "\n",
    "(El superscript $(1)$ indica que estamos hablando de la primera capa de la red, que coincide con la entrada).\n",
    "\n",
    "$$ \\theta^{(1)} = [\\theta_0^{(1)} \\ldots \\theta_n^{(1)}] $$\n",
    "\n",
    "Es el conjunto de parámetros para la combinación lineal calculados por la neurona de la capa 2 (también llamados _pesos_). \n",
    "\n",
    "Finalmente, obtenemos \n",
    "\n",
    "$$ h_\\theta(x) =  a^{(2)} \\in \\mathbb{R} = g(\\theta^{(1)}\\cdot x) $$\n",
    "\n",
    "siendo $g(z)$ la _función de activación_ (en nuestro ejemplo, la función logística o sigmoide). El valor de salida de cada neurona se conoce como _activación_. \n",
    "\n",
    "Observaciones:\n",
    "* El valor de salida de cada neurona $a^{(j)}_i$ se conoce como _activación_. El valor intermedio $z^{(j)}=\\theta^{(1)}\\cdot  x$ es conocido también como entrada ponderada de la neurona (y veremos más adelante la utilidad de identificarla por separado)\n",
    "* $x_0 = 1$, es llamado el sesgo (_bias term_), y se utiliza para representar la combinación lineal a través del producto interno de vectores\n",
    "\n",
    "- Existen funciones de activación alternativas a la sigmoide. Dos muy populares son ReLU (Rectified Linear Unit), y tangente hiperbólica:\n",
    " - ReLU: $f(x) = max(0,x)$\n",
    " - tanh: $f(x) = \\frac{sinh(x)}{cosh(x)}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Las redes neuronales son una generalización del ejemplo anterior: en cada una de las capas puede haber más de una neurona (que recibe como entrada los resultados de la capa anterior), y pueden introducirse capas intermedias (también llamadas _capas ocultas_). En cada capa, es usual introducir un _bias unit_ (que siempre vale 1), que cumple el mismo rol que $x_0$, es decir permitir manejar el término independiente en la combinación lineal. \n",
    "\n",
    "Por lo tanto, generalizando el caso anterior tendremos: \n",
    "\n",
    "\n",
    "\n",
    "$$ a^{(1)} \\in  \\mathbb{R}^{n} =  x = \\left[ \\begin{array}{l} x_0=1\\\\\\vdots\\\\x_n \\end{array}\\right] $$\n",
    "\n",
    "\n",
    "$$ a^{(j)} \\in  \\mathbb{R}^{S_j} =  \\left[ \\begin{array}{l} a^{(j)}_0=1\\\\\\vdots\\\\a^{(j)}_{s_j} \\end{array}\\right] = g(\\theta^{(j-1)}\\cdot a^{(j-1)})$$\n",
    "\n",
    "siendo $s_j$ el número de neuronas en la capa $j$, y $\\theta^{(j)}$ la matriz de pesos que define el mapeo desde la capa $j$ a la capa $j+1$. La matriz $\\theta^{(j)}$ tiene en sus filas los pesos asociados a la combinación lineal de las entradas de la unidad $i$ de la capa $j+1$, que son resultados de la activación de las unidades en la capa $j$:\n",
    "\n",
    "$$ \\theta^{(j)}= \\left ( \\begin{array} {cccc} \n",
    "\\theta^{(j)}_{10} & \\theta^{(j)}_{11} & \\cdots & \\theta^{(j)}_{1s_{j}}\\\\\n",
    "\\theta^{(j)}_{20} & \\theta^{(j)}_{21} & \\cdots & \\theta^{(j)}_{2s_{j}}\\\\\n",
    "\\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "\\theta^{(j)}_{s_{j+1}0} & \\theta^{(j)}_{21} & \\cdots & \\theta^{(j)}_{s_{j+1}s_{j}}\\\\\n",
    "\\end{array}\\right )$$\n",
    "\n",
    "Podemos observar que $\\theta^{(j)} \\in  \\mathbb{R}^{s_{j+1}} \\times \\mathbb{R^{s_{j}+1}}$ (tiene tantas filas como neuronas hay en la capa $j+1$, y tantas columnas como neuronas hay en la capa $j$, más las unidades de sesgo de cada capa. Cada valor $\\theta^{(j)}_{ik}$ de la matriz debe leerse como el peso asociado a la i-ésima neurona de la capa $j+1$, correspondiente a la entrada proveniente de la k-ésima neurona de la capa $j$.\n",
    "\n",
    "Este modelo de redes neuronales donde cada capa está conectada con la siguiente (y donde, por lo tanto, no existen loops) es conocido como _redes feedforward_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Forward propagation (Propagación hacia adelante)\n",
    "\n",
    "El proceso de calcular los valores de salida de cada capa, y utilizarlo como entrada para la siguiente, hasta obtener el valor final de $h_\\theta(x)$ es conocido como _forward propagation_. Mostraremos a través de algunos ejemplos cómo funciona en la práctica. \n",
    "\n",
    "Supongamos que tenemos una red neuronal con dos valores de entrada (que supondremos binarios) y queremos construir una red con calcule el OR lógico de ambos valores. Para ello, definiremos una arquitectura con dos entradas, y una sola neurona, que nos dará la salida necesaria. Comprobaremos que utilizando $\\theta^{(1)} = [-10\\ 20\\  20]$ estaremos computando la función que queremos. Primero calculamos el resultado de la red para la entrada $x=[1,0,0]$ (recordemos que agregamos un valor $x_0=1$ de sesgo): \n",
    "\n",
    "$$ x \\in  \\mathbb{R}^{3} = a^{(1)} = \\left[ \\begin{array}{c} 1\\\\0\\\\0\\\\ \\end{array}\\right]$$\n",
    "\n",
    "$$ a^{(2)} \\in  \\mathbb{R}^{1} = g(\\theta^{(1)}\\cdot x = g (-10+20*0+20*0) = g(-10) \\approx 0$$\n",
    "\n",
    "Es decir que cuando $x_1=0$ y $x_2=0$, entonces $h(x) \\approx 0$, lo cual corresponde a la definición de OR lógico. Análogamente, se puede ver que en las otras combinaciones de la entrada, se obtienen los valores adecuados para la función. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Para ver un caso más interesante, construiremos una red neuronal para calcular la función $XNOR$, que devuelve $1$ si ambas entradas valen $1$, o ambas entradas valen $0$. Esta función puede escribirse como $OR(AND(x_1,x_2),NOR(x_1,x_2))$ (comprobarlo), y a partir de esto construiremos una red neuronal de tres capas: las tres neuronas de la primera capa corresponden a las entradas $x_0, x_1, x_2$, la segunda capa (oculta), tiene dos neuronas: una computa la función $AND$ y la otra la función $NOR$. Finalmente, la tercera capa (de salida) tiene una sola neurona que computa el $OR$ de los resultados de las neuronas de la capa 2, para obtener el resultado. \n",
    "\n",
    "\n",
    "La entrada será igual que en el caso anterior: \n",
    "\n",
    "$$ x \\in  \\mathbb{R}^{3} = a^{(1)} = \\left[ \\begin{array}{c} x_0\\\\x_1\\\\x_2\\\\ \\end{array}\\right]$$\n",
    "\n",
    "En la capa 2, tendremos los parámetros correspondientes a la función $AND$ en la primera fila (verifíquelo en cada caso), y a los de $NOR$ en la segunda, lo que nos da la siguiente matriz de parámetros: \n",
    "\n",
    "$$\\theta^{(1)} = \\left [ \\begin{array}{rrr} -30&20&20\\\\10&-20&-20\\\\ \\end{array}\\right]$$\n",
    "\n",
    "En la capa 3, hay una sola neurona que calcula el $OR$ de sus entradas:\n",
    "\n",
    "$$\\theta^{(2)} = \\left [ \\begin{array}{rrr} -10&20&20 \\end{array}\\right]$$\n",
    "\n",
    "Podemos comprobar mediante forward propagation que nuestra red se comporta como esperamos. Supongamos que las dos entradas son 0: \n",
    "\n",
    "$$ x \\in  \\mathbb{R}^{3} = a^{(1)} = \\left[ \\begin{array}{c} 1\\\\0\\\\0\\\\ \\end{array}\\right]$$\n",
    "\n",
    "Obtenemos los valores de activación de la segunda capa: \n",
    "\n",
    "$$ a^{(2)} \\in  \\mathbb{R}^{2 \\times 1} = g(\\theta^{(1)}\\cdot a^{(1)})  = g ([-30\\  20]) \\approx [0\\  1]$$\n",
    "\n",
    "El primer valor de $ a^{(2)}$ es $0$, equivalente al $AND$ de las entradas, y el segundo es 1, el $NOR$ de las entradas. Con estos valores de salida como entrada para la ùnica neurona de salida, calculamos la activación: \n",
    "\n",
    "$$ a^{(3)} \\in  \\mathbb{R}^ = g(\\theta^{(2)}\\cdot a^{(2)})  = g ([10]) \\approx [1]$$\n",
    "\n",
    "(Atención! Entre los dos pasos anteriores, debe modificarse $a^{(2)}$, agregando un elemento de valor $1$ al comienzo del vector, para incluir el sesgo)\n",
    "\n",
    "Por lo tanto, nuestra funciòn devuelve $1$ cuando las dos entradas son 0.\n",
    "\n",
    "Repetimos el proceso para cuando $x_1=1$ y $x_2=0$: \n",
    "\n",
    "$$ x \\in  \\mathbb{R}^{3} = a^{(1)} = \\left[ \\begin{array}{c} 1\\\\1\\\\0\\\\ \\end{array}\\right] $$\n",
    "\n",
    "$$ a^{(2)} \\in  \\mathbb{R}^{2 \\times 1} = g(\\theta^{(1)}\\cdot a^{(1)})  = g ([-10\\  -10]) \\approx [0\\  0] $$\n",
    "\n",
    "$$ a^{(3)} \\in  \\mathbb{R}^ = g(\\theta^{(2)}\\cdot a^{(2)})  = g ([-10]) \\approx [0] $$\n",
    "\n",
    "Si completamos la tabla de valores, veremos que nuestra red neuronal computa la funciòn $XNOR$, como esperábamos. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clasificación multiclase\n",
    "\n",
    "Hasta el momento, las redes construidas tenìan solamente una neurona de salida, que computaba la función logística (o similar) para poder realizar clasificación binaria. ¿Còmo podemos utilizar las redes neuronales para clasificar entre màs de dos clases? \n",
    "\n",
    "La soluciòn pasa por definir varias neuronas en la capa de salida (podemos observar que el modelo no lo impide), y que la función $h_\\theta(x)$ devuelva un vector, cuyos elementos sean los valores de activación de cada una de esas neuronas. Los vectores tendràn la forma $[0 \\  0 \\ldots 1 \\ldots 0 \\  0]$, donde el ùnico 1 indica la clase que corresponde.\n",
    "\n",
    "Por ejemplo, si tenemos 4 clases posibles de salida, nuestros ejemplos de entrenamiento serán:\n",
    "\n",
    "$$ y^{(i)} \\in \\{ \\left[ \\begin{array}{c} 0\\\\0\\\\0\\\\1 \\end{array}\\right], \\left[ \\begin{array}{c} 0\\\\0\\\\1\\\\0 \\end{array}\\right], \\left[ \\begin{array}{c} 0\\\\1\\\\0\\\\0 \\end{array}\\right], \\left[ \\begin{array}{c} 1\\\\0\\\\0\\\\0 \\end{array}\\right] $$\n",
    "\n",
    "Y la misma forma tendrá $h_\\theta(x)$. Al componente i-esimo de $h_\\theta(x)$ lo denotaremos $(h_\\theta(x))_i$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Aprendizaje en Redes Neuronales\n",
    "\n",
    "Al igual que en los métodos anteriores, es importante entender cómo funciona el aprendizaje en redes neuronales. En este caso, lo que intentaremos aprender a partir de los datos de entrenamiento será las matrices de pesos $\\Theta^{(j)}$ de las diferentes capas. \n",
    "\n",
    "Fijemos algunas definiciones:\n",
    "\n",
    "* $L$ es el número de capas de la red neuronal\n",
    "* $s_l$ es el número de neuronas (sin contar la neurona de sesgo) de la capa $l$\n",
    "* $K$ es el número de neuronas en la capa de salida (por lo tanto, $h_\\Theta(x) \\in \\mathbb{R}^K$)\n",
    "\n",
    "Una función de costo para redes neuronales que podemos utilizar es muy similar a la utilizada para regresiòn logística:\n",
    "\n",
    "$$ J(\\Theta) = - \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=1}^K \\left[ y_k^{(i)}\\ \\log ((h_\\theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\\ \\log (1 - (h_\\theta(x^{(i)}))_k)\\right] + \\frac{\\lambda}{2m} \\sum_{l=1}^{L-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(\\theta^{(l)}_{ji})^2 $$\n",
    "\n",
    "Por una parte, la función de costo sumará los costos de todas las unidades de la capa de salida. Por otra, para la regularización, buscará penalizar los parámetros muy grandes para todas las neuronas de la red.\n",
    "\n",
    "Una función alternativa podría ser: \n",
    "\n",
    "$$J(\\theta) = - \\frac{1}{2m} \\sum_{i=1}^m || y^{(i)} - a^{(L)}||^2 $$\n",
    "\n",
    "donde los valores de $a^{(L)}$ son los correspondientes al i-esimo ejemplo de entrenamiento (esta función es llamada de costo cuadrático... y es la misma que la utilizada en los problemas de regresión lineal)\n",
    "\n",
    "Estas funciones no son las únicas posibles. De hecho, basta con suponer que la función de costo puede escribirse como un promedio de los costos de los ejemplos de entrenamiento, y que es que puede ser escrita como función de las salidas de la red. Por una lista de funciones de costo posibles, consulte este [link](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications). A partir de la primera propiedad, eliminaremos los supraíndices en los cálculos y supondremos que estamos calculando el costo para un ejemplo dado. \n",
    "\n",
    "\n",
    "El siguiente paso es, igual que hicimos con regresión logística, intentar minimizar la función de costo. Para esto utilizaremos nuevamente descenso por gradiente (o algún otro método de minimización numérica), pero para ello debemos calcular las derivadas parciales de $J(\\theta)$ respecto a cada uno de los pesos de la red. El algoritmo de backpropagation, precisamente, permite calcular de forma eficiente estas derivadas.\n",
    "\n",
    "La idea del algoritmos es calcular, para cada neurona, un valor $\\delta^{(i)}_j$ que generaliza la idea del \"error\" cometido por la neurona, respecto al valor de la instancia de entrenamiento correspondiente. Para ser más exactos, \n",
    "\n",
    "$$\\delta^{(l)}_j = \\frac{\\partial J  } {\\partial z^{(l)}_j}  $$ \n",
    "\n",
    "es decir la derivada parcial de la función de costo respecto a $z^{(l)}_j $. Intuitivamente, si incrementamos en $\\Delta z^{(l)}_j$ el valor de la combinación lineal de la entrada, la salida de la neurona será  $g(z^{(l)}_j+\\Delta z^{(l)}_j)$. \n",
    "\n",
    "Este valor se propagará por la red, para llegar a un cambio final de $\\frac{\\partial J}{\\partial z^{(l)}_j}  \\Delta z^{(l)}_j$. En caso de que esta derivada final tenga un valor grande, y modifiquemos el valor $\\Delta z^{(l)}_j$ con signo opuesto, podremos reducir el valor de la función de costo (siguiendo el principio del descenso por gradiente). Si es el valor de la derivada es cercano a 0, entonces ese parámetro no modifica mucho el costo, por lo que no aporta al costo final (y por lo tanto, es un valor razonable). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Esta diferencia puede calcularse  para las neuronas de salida, luego de haber calculado (vía forward propagation) los valores de activación $a^{(L)}$ de la capa de salida :\n",
    "\n",
    "$$ \\delta^{(L)} = \\nabla_a J \\odot g'(z^{(L)})$$\n",
    "\n",
    "Esto, para las funciones de costo que presentamos es equivalente a: \n",
    "\n",
    "$$ \\delta^{(L)} = (a^{(L)}-y) \\odot g'(z^{(L)})$$\n",
    "\n",
    "siendo $y$ el valor objetivo de la instancia de entrenamiento, y donde $\\odot$ representa al producto de Hadamard (es decir el producto componente a componente de los vectores involucrados). El primer factor está relacionado a la derivada de la función de costo respecto a cada uno de los valores de activación de la capa de salida (y por lo tanto mide qué tanto cambia el costo como función del valor de activación), y el segundo a la derivada de la función de activación (es decir, cómo está cambiando la función de activación respecto a su entrada). \n",
    "\n",
    "En el caso de la función sigmoide, su derivada puede calcularse de forma muy sencilla: $g'(z)=g(z)(1-g(z))$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Una vez obtenidos estos valores en la capa final, \"propagaremos hacia atrás\" ese error, calculando los $\\delta^{(l)}$ de la siguiente forma: \n",
    "\n",
    "$$ \\delta^{(l)} = (\\theta^{(l)})^T \\delta^{(l+1)} \\odot g'(z^{(l)}) $$\n",
    "\n",
    "siendo \n",
    "\n",
    "$$ z^{(l+1)} = \\theta^{(l)}\\cdot a^{(l)}$$ \n",
    "\n",
    "\n",
    "\n",
    "y donde $g'(z^{(l)})$ es la derivada de $g$ evaluada en cada uno de los elementos de $z^{(l)}$ \n",
    "\n",
    "A partir de $\\delta^{(l+1)}_i$ podemos calcular las derivadas parciales (ignorando la regularización):\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial\\theta^{(l)}_{ij}} J(\\theta) = a^{(l)}_j\\delta^{(l+1)}_i$$\n",
    "\n",
    "Puede verse que necesitamos calcular primero la última capa, luego la anteúltima, y así sucesivamente hasta la segunda capa (la primera capa es la capa de entrada, y por lo tanto no tiene \"error\"). \n",
    "\n",
    "Algunas observaciones: \n",
    "\n",
    "* Si la activación de la neurona es cercana a 0 ( $a^{(l)}_j \\approx 0$), entonces la derivada será pequeña, y por lo tanto la modificación en el parámetro al aplicar descenso por gradiente será también pequeño. Decimos en este caso que el parámetro está _aprendiendo lentamente_.\n",
    "\n",
    "* Cuando una neurona de salida tiene un valor de activación cercano a 0, o cercano a 1, y dada la forma de la función sigmoide , tendremos $g'(z_j^{(L)})\\approx0$: el parámetro de esta neurona aprenderá lentamente, y diremos que la neurona está _saturada_. Lo mismo puede suceder en las capas anteriores.  Esto hace que en una neurona saturada, los pesos que llegan a esa neurona aprenderán lentamente. \n",
    "\n",
    "* Resumiento: un parámetro aprenderá lentamente si la neurona de entrada es de baja activación o la de salida de de alta o baja activación. \n",
    "\n",
    "Es interesante observar que las ecuaciones que permiten calcular las derviadas parciales no dependen de la función de activación. Por lo tanto, es posible elegir funciones de activación diferentes para lograr ciertos comportamientos de las redes neuronales. Esto ha sido un área de activa investigación en los últimos años. Por ejemplo, para evitar que una neurona se sature (i.e. se acerque a 0 o 1), es posible definir una función de activación siempre positiva y que no se acerque a 0. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. El algoritmo de backpropagation\n",
    "\n",
    "Resumiendo, el algoritmo de backpropagation nos permite calcular el gradiente de la función de costo, y se resume así: \n",
    "\n",
    "Dado el conjunto de entrenamiento $\\{(x^{(1)},y^{(1)}, \\ldots , (x^{(m)},y^{(m)}) \\}$, para cada ejemplo $x=x^{(i)}$:\n",
    "\n",
    "1. Definir la capa 1 de entrada: $a^{(1)}$ := $x$\n",
    "2. Para cada $l=2,3,\\ldots, L$ calcular $z^{(l)}=\\Theta^{(l-1)} a^{(l-1)}$ y $a^{(l)} = g(z^{(l)})$\n",
    "3. Calcular $\\delta^{(L)} = (a^{(L)}-y) \\odot g'(z^{(L)})$\n",
    "4. Propagar el error hacia atrás: para cada $l = L-1,L-2, \\ldots, 2$ calcular $\\delta^{(l)} = (\\Theta^{(l)})^T \\delta^{(l+1)} \\odot g'(z^{(l)})$\n",
    "5. El gradiente de la función de costo será: \n",
    "\n",
    "$$  \\frac{\\partial J}{\\partial\\theta^{(l)}_{jk} } = a^{(l)}_k\\delta^{(l+1)}_j$$\n",
    "\n",
    "Luego de calculados las derivadas para cada uno de los parámetros y para cada uno de los ejemplos de entrenamiento, utilizamos descenso por gradiente para actualizar los pesos de las capas $l=L,L-1,L-2,\\ldots ,2$: \n",
    "\n",
    "$$ \\Theta^{(l)} = \\Theta^{(l)} - \\alpha  \\sum_x \\delta^{x,(l+1)} \\cdot (a^{x,l})^T$$\n",
    "\n",
    "siendo $\\delta^{x,l}$ el valor de  $\\delta^{l}$ para la instancia $x$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Aprendizaje de redes neuronales en la práctica\n",
    "\n",
    "Si bien backpropagation y descenso por gradiente es todo lo que necesitamos para aprender los pesos de una red neuronal, en la práctica existen muchos detalles que deben tenerse en cuenta para lograr una implementación eficiente. Mencionaremos algunos en esta sección. Por detalles, el capítulo \"Improving the way neural networks learn\" del libro de Nielsen mencionado en las referencia, aporta muchos detalles.\n",
    "\n",
    "**Función de entropía cruzada**\n",
    "\n",
    "La primera de las dos funciones de costo presentadas (llamada entropía cruzada) presentadas tiene una interesante propiedad: el valor de las derivadas parciales de la función de costo no dependen de la derivada de $g$. Por ejemplo, para la última capa: \n",
    "\n",
    "$$ \\delta^{(L)} = (a^{(L)}-y)$$\n",
    "\n",
    "Esto hace que (a diferencia de la función de costo cuadrático), no se produzca un enlentecimiento del aprendizaje cuando las neuronas están saturadas.\n",
    "\n",
    "**Softmax**\n",
    "\n",
    "En una capa softmax, en lugar de aplicar la función sigmoide, utilizamos la función softmax, donde en el denominador la suma es sobre todas las neuronas de salida: \n",
    "\n",
    "$$ a^{(L)}_j = \\frac{e^{z^L_j}}{\\sum_k e^{z^L_j}}$$\n",
    "\n",
    "Puede verificarse que la suma de las activaciones siempre es 1. Como también son siempre positivos, las salidas de una capa softmax forma una distribución de probabilidad. Y por lo tanto pueden utilizarse para interpretar un conjunto de salidas como la distribución de probabilidad de las diferentes clases (lo cual no es posible con una capa de salida basada en la sigmoide). Puede demostrarse que la capa softmax también evita el problema del enlentencimiento en el aprendizaje (si se utiliza con una función de costo ligeramente difernete (conocida como log-likelihood). \n",
    "\n",
    "** Inicialización de los parámetros **\n",
    "\n",
    "Para evitar que, al aprender, todos los parámetros ajusten al mismo valor, debemos inicializar los parámetros en valores diferentes a 0. Para eso, una solución es utilizar valores aleatorios entre $[-\\epsilon, \\epsilon]$ para inicializar cada uno de los parámetros. En el libro mencionado en las referencias se discuten algunas técnicas más avanzadas para inicializar los parámetros. \n",
    "\n",
    "** Gradient checking **\n",
    "\n",
    "Cuando se está implementando backpropagation, es muy difícil detectar errores pequeños en el funcionamiento del algoritmo. Una forma mucho más sencilla (pero muchísimo más lenta) de aproximarse al cálculo del gradiente es la siguiente: dado un valor pequeño $\\epsilon$ (por ejemplo, $10^{-4}$), calcular:\n",
    "\n",
    "$$   \\frac{\\partial J(\\Theta)}{\\partial\\Theta } \\approx \\frac{J(\\Theta+\\epsilon ) - J(\\Theta-\\epsilon )}{2\\epsilon}$$\n",
    "\n",
    "y, si tenemos múltiples matrices:\n",
    "\n",
    "$$   \\frac{\\partial J(\\Theta)}{\\partial\\Theta_j } \\approx \\frac{J(\\Theta_1,\\Theta_2,\\ldots, \\Theta_j+\\epsilon ,\\ldots, \\Theta_n)- J(\\Theta_1,\\Theta_2,\\ldots, \\Theta_j-\\epsilon ,\\ldots, \\Theta_n)}{2\\epsilon}$$\n",
    "\n",
    "Esta aproximación nos permite verificar que los valores que estamos calculando con backpropagation de las derivadas son correctos. Por supuesto, esto se utiliza durante el desarrollo del algoritmo: para el ajuste final de los parámetros se desactiva.\n",
    "\n",
    "### 7. Deep Learning\n",
    "\n",
    "A partir de los fundamentos aquí presentado, existen muchos modelos diferentes de redes neuronales, que han resultado muy útiles en diferentes tareas de aprendizaje automático. Aunque exceden el alcance de este curso, esperamos que los conceptos fundamentales aquí presentados ayuden a entenderlas, tanto desde su diseño como en su aplicación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias y material adicional\n",
    "Las notas están basadas en el curso de la Universidad de Stanford, y de las presentaciones y [material](http://cs229.stanford.edu/notes/cs229-notes-deep_learning.pdf) asociados (disponibles a través de la plataforma Coursera). Sugerimos recurrir a ambas fuentes para más detalles respecto a los métodos aquí presentados. Si se quiere profundizar en su aplicación, recomendamos el libro \"[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)\" de Michael Nielsen. El artículo \"[Calculus on Computational Graphs: Backpropagation](http://colah.github.io/posts/2015-08-Backprop/)\" de Chris Olah, presenta los fundamentos matemáticos básicos de los grafos computacionales y de la diferenciación reversa.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
